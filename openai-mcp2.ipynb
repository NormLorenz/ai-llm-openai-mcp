{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3Kd2jJECqQzdQc02rZHwr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NormLorenz/ai-llm-openai-mcp/blob/main/openai-mcp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using OpenAI Agents with a MCP Server"
      ],
      "metadata": {
        "id": "f-IddCP5dWDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install fastmcp openai nest_asyncio\n"
      ],
      "metadata": {
        "id": "9a9UkP4yeqgz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets up and runs a FastMCP server that acts as a weather service.\n",
        "\n",
        "It uses fastmcp to create an agent that can interact with the National Weather Service (NWS) API. It defines several Tools like get_forecast, get_alerts, and health_check which perform specific actions. The server is then launched in a background thread to make these tools and resources accessible via HTTP, specifically configured for notebook compatibility.\n",
        "\n",
        "The MCP server is based upon code found at https://github.com/lxchst/weather-server-python/blob/main/src/weather/server.py"
      ],
      "metadata": {
        "id": "8ww5TdvdC5yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The MCP Server\n",
        "\n",
        "from fastmcp import FastMCP\n",
        "import nest_asyncio\n",
        "import threading\n",
        "import time\n",
        "from typing import Any\n",
        "import httpx\n",
        "import warnings\n",
        "\n",
        "# Filter specific DeprecationWarning from jupyter_client\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='jupyter_client')\n",
        "\n",
        "# Constants\n",
        "NWS_API_BASE = \"https://api.weather.gov\"\n",
        "USER_AGENT = \"weather-app/1.0\"\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "mcp = FastMCP(\n",
        "    name=\"WeatherServer\",\n",
        "    instructions=\"Provides an up to date weather forecast and alerts for any location and also includes a health check.\"\n",
        ")\n",
        "\n",
        "async def make_nws_request(url: str) -> dict[str, Any] | None:\n",
        "    \"\"\"Make a request to the NWS API with proper error handling.\"\"\"\n",
        "    headers = {\"User-Agent\": USER_AGENT, \"Accept\": \"application/geo+json\"}\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        try:\n",
        "            response = await client.get(url, headers=headers, timeout=30.0)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "\n",
        "def format_alert(feature: dict) -> str:\n",
        "    \"\"\"Format an alert feature into a readable string.\"\"\"\n",
        "    props = feature[\"properties\"]\n",
        "    return f\"\"\"\n",
        "        Event: {props.get(\"event\", \"Unknown\")}\n",
        "        Area: {props.get(\"areaDesc\", \"Unknown\")}\n",
        "        Severity: {props.get(\"severity\", \"Unknown\")}\n",
        "        Description: {props.get(\"description\", \"No description available\")}\n",
        "        Instructions: {props.get(\"instruction\", \"No specific instructions provided\")}\n",
        "        \"\"\"\n",
        "\n",
        "@mcp.tool\n",
        "def greet(name: str) -> str:\n",
        "    \"\"\"Greet a person by their name.\n",
        "\n",
        "    Args:\n",
        "        name: The name of the person to greet.\n",
        "    \"\"\"\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_alerts(state: str) -> str:\n",
        "    \"\"\"Get weather alerts for a US state.\n",
        "\n",
        "    Args:\n",
        "        state: Two-letter US state code (e.g. CA, NY)\n",
        "    \"\"\"\n",
        "    url = f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n",
        "    data = await make_nws_request(url)\n",
        "\n",
        "    if not data or \"features\" not in data:\n",
        "        return \"Unable to fetch alerts or no alerts found.\"\n",
        "\n",
        "    if not data[\"features\"]:\n",
        "        return \"No active alerts for this state.\"\n",
        "\n",
        "    alerts = [format_alert(feature) for feature in data[\"features\"]]\n",
        "    return \"\\n---\\n\".join(alerts)\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_forecast(latitude: float, longitude: float) -> str:\n",
        "    \"\"\"Get weather forecast for a location.\n",
        "\n",
        "    Args:\n",
        "        latitude: Latitude of the location\n",
        "        longitude: Longitude of the location\n",
        "    \"\"\"\n",
        "    # First get the forecast grid endpoint\n",
        "    points_url = f\"{NWS_API_BASE}/points/{latitude},{longitude}\"\n",
        "    points_data = await make_nws_request(points_url)\n",
        "\n",
        "    if not points_data:\n",
        "        return \"Unable to fetch forecast data for this location.\"\n",
        "\n",
        "    # Get the forecast URL from the points response\n",
        "    forecast_url = points_data[\"properties\"][\"forecast\"]\n",
        "    forecast_data = await make_nws_request(forecast_url)\n",
        "\n",
        "    if not forecast_data:\n",
        "        return \"Unable to fetch detailed forecast.\"\n",
        "\n",
        "    # Format the periods into a readable forecast\n",
        "    periods = forecast_data[\"properties\"][\"periods\"]\n",
        "    forecasts = []\n",
        "    for period in periods[:5]:  # Only show next 5 periods\n",
        "        forecast = f\"\"\"\n",
        "        {period[\"name\"]}:\n",
        "        Temperature: {period[\"temperature\"]}Â°{period[\"temperatureUnit\"]}\n",
        "        Wind: {period[\"windSpeed\"]} {period[\"windDirection\"]}\n",
        "        Forecast: {period[\"detailedForecast\"]}\n",
        "        \"\"\"\n",
        "        forecasts.append(forecast)\n",
        "\n",
        "    return \"\\n---\\n\".join(forecasts)\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "def health_check():\n",
        "    \"\"\"Returns the health status of the server.\"\"\"\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "\n",
        "# Define the function to run the server\n",
        "def run_server():\n",
        "    # Use transport=\"streamable-http\" for compatibility with notebooks/Colab\n",
        "    print(\"ðŸš€ Starting FastMCP server in background thread...\")\n",
        "    mcp.run(transport=\"streamable-http\", host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start the server in a separate thread\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Give the server a moment to start up\n",
        "time.sleep(5)\n",
        "print(\"âœ… Server should be running. Access it at http://localhost:8000/mcp\")\n"
      ],
      "metadata": {
        "id": "ey18Q7l-DLM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code connects to a local FastMCP server to retrieve and then call its available tools. It defines several asynchronous functions, each designed to interact with a specific tool on the server (like greet, get_alerts, get_forecast, health_check, and list_tools), and then it executes these functions to demonstrate how to use the server's capabilities."
      ],
      "metadata": {
        "id": "DhPb2BvaIX0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First try to connect to the MCP server.\n",
        "\n",
        "import asyncio\n",
        "import warnings\n",
        "from fastmcp import Client\n",
        "\n",
        "# Filter specific DeprecationWarning from jupyter_client\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='jupyter_client')\n",
        "\n",
        "client = Client(\"http://localhost:8000/mcp\")\n",
        "\n",
        "async def call_greet(name: str):\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"greet\", {\"name\": name})\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_get_alerts(name: str):\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"get_alerts\", {\"state\": name})\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_get_forecast(latitude: float, longitude: float):\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"get_forecast\", {\"latitude\": latitude, \"longitude\": longitude})\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_health_check():\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"health_check\")\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_list_tools():\n",
        "    async with client:\n",
        "        result = await client.list_tools()\n",
        "        for tool in result:\n",
        "            print(tool)\n",
        "\n",
        "asyncio.run(call_greet(\"Norm\"))\n",
        "asyncio.run(call_get_alerts(\"WA\"))\n",
        "asyncio.run(call_health_check())\n",
        "asyncio.run(call_get_forecast(47.7179, -116.9516))\n",
        "asyncio.run(call_list_tools())\n"
      ],
      "metadata": {
        "id": "cBgZJGGYiMYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates how to integrate a FastMCP server with an OpenAI agent. It first connects to the local FastMCP server to retrieve the tools it exposes (like weather forecast and alerts). These tools are then used to create an OpenAI agent. Finally, the agent is run with a user input, and it leverages the provided FastMCP tools to find the answer, in this case, asking about the weather in Seattle."
      ],
      "metadata": {
        "id": "9OC4Z1Ff0Nhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "T1nlA0XDyNbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import asyncio\n",
        "from fastmcp import Client\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Filter specific DeprecationWarning from jupyter_client\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='jupyter_client')\n",
        "\n",
        "# Initialize API key\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "MCP_SERVER_URL = \"http://localhost:8000/mcp\"\n",
        "\n",
        "async def main():\n",
        "    openai_client = OpenAI()\n",
        "    assistant = None\n",
        "\n",
        "    try:\n",
        "        # Connect to MCP server and keep connection open\n",
        "        async with Client(MCP_SERVER_URL) as mcp_client:\n",
        "            # Fetch tools\n",
        "            mcp_tools = await mcp_client.list_tools()\n",
        "\n",
        "            # Convert to OpenAI format\n",
        "            agent_tools = [{\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tool.name,\n",
        "                    \"description\": tool.description or \"\",\n",
        "                    \"parameters\": tool.inputSchema\n",
        "                }\n",
        "            } for tool in mcp_tools]\n",
        "            print(agent_tools)\n",
        "\n",
        "            # Create assistant\n",
        "            assistant = openai_client.assistants.create(\n",
        "                model=\"gpt-4-turbo\",  # Valid model name\n",
        "                name=\"MCP Assistant\",\n",
        "                instructions=\"Use the provided tools when helpful.\",\n",
        "                tools=agent_tools\n",
        "            )\n",
        "\n",
        "            print(f\"Assistant created: {assistant.id}\")\n",
        "\n",
        "            # Create thread and message\n",
        "            thread = openai_client.threads.create()\n",
        "            openai_client.threads.messages.create(\n",
        "                thread_id=thread.id,\n",
        "                role=\"user\",\n",
        "                content=\"What is the weather in Spokane?\"\n",
        "            )\n",
        "\n",
        "            # Run with tool call handling\n",
        "            run = openai_client.threads.runs.create_and_poll(\n",
        "                thread_id=thread.id,\n",
        "                assistant_id=assistant.id\n",
        "            )\n",
        "\n",
        "            # Handle tool calls\n",
        "            while run.status == 'requires_action':\n",
        "                tool_outputs = []\n",
        "\n",
        "                for tool_call in run.required_action.submit_tool_outputs.tool_calls:\n",
        "                    # Call MCP server\n",
        "                    result = await mcp_client.call_tool(\n",
        "                        tool_call.function.name,\n",
        "                        arguments=eval(tool_call.function.arguments)  # Better: json.loads()\n",
        "                    )\n",
        "\n",
        "                    tool_outputs.append({\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"output\": str(result)\n",
        "                    })\n",
        "\n",
        "                # Submit outputs and continue\n",
        "                run = openai_client.threads.runs.submit_tool_outputs_and_poll(\n",
        "                    thread_id=thread.id,\n",
        "                    run_id=run.id,\n",
        "                    tool_outputs=tool_outputs\n",
        "                )\n",
        "\n",
        "            # Get final response\n",
        "            if run.status == 'completed':\n",
        "                messages = openai_client.threads.messages.list(thread_id=thread.id)\n",
        "                for message in messages.data:\n",
        "                    if message.role == \"assistant\":\n",
        "                        print(message.content[0].text.value)\n",
        "                        break\n",
        "            else:\n",
        "                print(f\"Run ended with status: {run.status}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    finally:\n",
        "        # Cleanup\n",
        "        if assistant:\n",
        "            openai_client.assistants.delete(assistant.id)\n",
        "\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "a8pgFKliqgvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try again https://github.com/openai/openai-agents-python"
      ],
      "metadata": {
        "id": "q60-lbgSkgKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install fastmcp nest_asyncio\n",
        "!pip install openai-agents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9rS-34kZjfDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import asyncio\n",
        "from fastmcp import Client\n",
        "from agents import Agent, Runner, function_tool\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Filter specific DeprecationWarning from jupyter_client\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='jupyter_client')\n",
        "\n",
        "# Initialize API key\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "MCP_SERVER_URL = \"http://localhost:8000/mcp\"\n",
        "\n",
        "async def main():\n",
        "\n",
        "    # Connect to MCP server and keep connection open\n",
        "    async with Client(MCP_SERVER_URL) as mcp_client:\n",
        "        # Fetch tools\n",
        "        mcp_tools = await mcp_client.list_tools()\n",
        "\n",
        "        # Convert to OpenAI format\n",
        "        agent_tools = [{\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": tool.name,\n",
        "                \"description\": tool.description or \"\",\n",
        "                \"parameters\": tool.inputSchema\n",
        "            }\n",
        "        } for tool in mcp_tools]\n",
        "        print(agent_tools)\n",
        "\n",
        "        @function_tool\n",
        "        def get_weather(city: str) -> str:\n",
        "          \"\"\"Get the weather in a city.\n",
        "\n",
        "          Args:\n",
        "              city: The name of the city.\n",
        "          \"\"\"\n",
        "          return f\"The weather in {city} is sunny.\"\n",
        "\n",
        "        agent = Agent(\n",
        "            name=\"Hello world\",\n",
        "            instructions=\"You are a helpful agent.\",\n",
        "            tools=agent_tools,\n",
        "            model=\"gpt-4-turbo\" # Specify the model here\n",
        "        )\n",
        "\n",
        "        result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
        "        print(result.final_output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main() # Run the coroutine directly within the existing event loop"
      ],
      "metadata": {
        "cellView": "code",
        "id": "lEJkpX0_hrNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import asyncio\n",
        "from fastmcp import Client\n",
        "from agents import Agent, Runner, function_tool\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module='jupyter_client')\n",
        "\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "MCP_SERVER_URL = \"http://localhost:8000/mcp\"\n",
        "\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        async with Client(MCP_SERVER_URL) as mcp_client:\n",
        "            # Fetch and convert MCP tools\n",
        "            mcp_tools = await mcp_client.list_tools()\n",
        "            agent_tools: list[dict[str, str]] = [{\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": tool.name,\n",
        "                    \"description\": tool.description or \"\",\n",
        "                    \"parameters\": tool.inputSchema\n",
        "                }\n",
        "            } for tool in mcp_tools]\n",
        "\n",
        "            # print for all to see\n",
        "            print(agent_tools)\n",
        "\n",
        "            # Create agent with both MCP and local tools\n",
        "            agent = Agent(\n",
        "                name=\"Weather Assistant\",\n",
        "                instructions=\"You are a helpful agent that can check weather.\",\n",
        "                tools=agent_tools,\n",
        "                model=\"gpt-4o\"\n",
        "            )\n",
        "\n",
        "            result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n",
        "            print(f\"Result: {result.final_output}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ],
      "metadata": {
        "id": "PEgGsuvVvl9S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}