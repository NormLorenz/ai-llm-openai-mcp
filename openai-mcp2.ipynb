{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQvncL2NB+cpTesKDFzgz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NormLorenz/ai-llm-openai-mcp/blob/main/openai-mcp2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using OpenAI Agents with a MCP Server"
      ],
      "metadata": {
        "id": "f-IddCP5dWDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install fastmcp openai nest_asyncio\n"
      ],
      "metadata": {
        "id": "9a9UkP4yeqgz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code sets up and runs a FastMCP server that acts as a weather service.\n",
        "\n",
        "It uses fastmcp to create an agent that can interact with the National Weather Service (NWS) API. It defines several Tools like get_forecast, get_alerts, and health_check which perform specific actions. The server is then launched in a background thread to make these tools and resources accessible via HTTP, specifically configured for notebook compatibility.\n",
        "\n",
        "The MCP server is based upon code found at https://github.com/lxchst/weather-server-python/blob/main/src/weather/server.py"
      ],
      "metadata": {
        "id": "8ww5TdvdC5yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The MCP Server\n",
        "\n",
        "from fastmcp import FastMCP\n",
        "import nest_asyncio\n",
        "import threading\n",
        "import time\n",
        "from typing import Any\n",
        "import httpx\n",
        "\n",
        "# Constants\n",
        "NWS_API_BASE = \"https://api.weather.gov\"\n",
        "USER_AGENT = \"weather-app/1.0\"\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "mcp = FastMCP(\n",
        "    name=\"WeatherServer\",\n",
        "    instructions=\"Provides an up to date weather forecast and alerts for any location and also includes a health check.\"\n",
        ")\n",
        "\n",
        "async def make_nws_request(url: str) -> dict[str, Any] | None:\n",
        "    \"\"\"Make a request to the NWS API with proper error handling.\"\"\"\n",
        "    headers = {\"User-Agent\": USER_AGENT, \"Accept\": \"application/geo+json\"}\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        try:\n",
        "            response = await client.get(url, headers=headers, timeout=30.0)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "\n",
        "def format_alert(feature: dict) -> str:\n",
        "    \"\"\"Format an alert feature into a readable string.\"\"\"\n",
        "    props = feature[\"properties\"]\n",
        "    return f\"\"\"\n",
        "        Event: {props.get(\"event\", \"Unknown\")}\n",
        "        Area: {props.get(\"areaDesc\", \"Unknown\")}\n",
        "        Severity: {props.get(\"severity\", \"Unknown\")}\n",
        "        Description: {props.get(\"description\", \"No description available\")}\n",
        "        Instructions: {props.get(\"instruction\", \"No specific instructions provided\")}\n",
        "        \"\"\"\n",
        "\n",
        "@mcp.tool\n",
        "def greet(name: str) -> str:\n",
        "    \"\"\"Greet a person by their name.\n",
        "\n",
        "    Args:\n",
        "        name: The name of the person to greet.\n",
        "    \"\"\"\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_alerts(state: str) -> str:\n",
        "    \"\"\"Get weather alerts for a US state.\n",
        "\n",
        "    Args:\n",
        "        state: Two-letter US state code (e.g. CA, NY)\n",
        "    \"\"\"\n",
        "    url = f\"{NWS_API_BASE}/alerts/active/area/{state}\"\n",
        "    data = await make_nws_request(url)\n",
        "\n",
        "    if not data or \"features\" not in data:\n",
        "        return \"Unable to fetch alerts or no alerts found.\"\n",
        "\n",
        "    if not data[\"features\"]:\n",
        "        return \"No active alerts for this state.\"\n",
        "\n",
        "    alerts = [format_alert(feature) for feature in data[\"features\"]]\n",
        "    return \"\\n---\\n\".join(alerts)\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "async def get_forecast(latitude: float, longitude: float) -> str:\n",
        "    \"\"\"Get weather forecast for a location.\n",
        "\n",
        "    Args:\n",
        "        latitude: Latitude of the location\n",
        "        longitude: Longitude of the location\n",
        "    \"\"\"\n",
        "    # First get the forecast grid endpoint\n",
        "    points_url = f\"{NWS_API_BASE}/points/{latitude},{longitude}\"\n",
        "    points_data = await make_nws_request(points_url)\n",
        "\n",
        "    if not points_data:\n",
        "        return \"Unable to fetch forecast data for this location.\"\n",
        "\n",
        "    # Get the forecast URL from the points response\n",
        "    forecast_url = points_data[\"properties\"][\"forecast\"]\n",
        "    forecast_data = await make_nws_request(forecast_url)\n",
        "\n",
        "    if not forecast_data:\n",
        "        return \"Unable to fetch detailed forecast.\"\n",
        "\n",
        "    # Format the periods into a readable forecast\n",
        "    periods = forecast_data[\"properties\"][\"periods\"]\n",
        "    forecasts = []\n",
        "    for period in periods[:5]:  # Only show next 5 periods\n",
        "        forecast = f\"\"\"\n",
        "        {period[\"name\"]}:\n",
        "        Temperature: {period[\"temperature\"]}Â°{period[\"temperatureUnit\"]}\n",
        "        Wind: {period[\"windSpeed\"]} {period[\"windDirection\"]}\n",
        "        Forecast: {period[\"detailedForecast\"]}\n",
        "        \"\"\"\n",
        "        forecasts.append(forecast)\n",
        "\n",
        "    return \"\\n---\\n\".join(forecasts)\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "def health_check():\n",
        "    \"\"\"Returns the health status of the server.\"\"\"\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "\n",
        "# Define the function to run the server\n",
        "def run_server():\n",
        "    # Use transport=\"streamable-http\" for compatibility with notebooks/Colab\n",
        "    print(\"ðŸš€ Starting FastMCP server in background thread...\")\n",
        "    mcp.run(transport=\"streamable-http\", host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start the server in a separate thread\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Give the server a moment to start up\n",
        "time.sleep(5)\n",
        "print(\"âœ… Server should be running. Access it at http://localhost:8000/mcp\")\n"
      ],
      "metadata": {
        "id": "ey18Q7l-DLM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code connects to a local FastMCP server to retrieve and then call its available tools. It defines several asynchronous functions, each designed to interact with a specific tool on the server (like greet, get_alerts, get_forecast, health_check, and list_tools), and then it executes these functions to demonstrate how to use the server's capabilities."
      ],
      "metadata": {
        "id": "DhPb2BvaIX0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First try to connect to the MCP server.\n",
        "\n",
        "import asyncio\n",
        "from fastmcp import Client\n",
        "\n",
        "client = Client(\"http://localhost:8000/mcp\")\n",
        "\n",
        "async def call_greet(name: str):\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"greet\", {\"name\": name})\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_get_alerts(name: str):\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"get_alerts\", {\"state\": name})\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_get_forecast(latitude: float, longitude: float):\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"get_forecast\", {\"latitude\": latitude, \"longitude\": longitude})\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_health_check():\n",
        "    async with client:\n",
        "        result = await client.call_tool(\"health_check\")\n",
        "        print(result)\n",
        "\n",
        "\n",
        "async def call_list_tools():\n",
        "    async with client:\n",
        "        result = await client.list_tools()\n",
        "        for tool in result:\n",
        "            print(tool)\n",
        "\n",
        "asyncio.run(call_greet(\"Norm\"))\n",
        "asyncio.run(call_get_alerts(\"WA\"))\n",
        "asyncio.run(call_health_check())\n",
        "asyncio.run(call_get_forecast(47.7179, -116.9516))\n",
        "asyncio.run(call_list_tools())\n"
      ],
      "metadata": {
        "id": "cBgZJGGYiMYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates how to integrate a FastMCP server with an OpenAI agent. It first connects to the local FastMCP server to retrieve the tools it exposes (like weather forecast and alerts). These tools are then used to create an OpenAI agent. Finally, the agent is run with a user input, and it leverages the provided FastMCP tools to find the answer, in this case, asking about the weather in Seattle."
      ],
      "metadata": {
        "id": "9OC4Z1Ff0Nhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastmcp import Client\n",
        "from openai import OpenAI\n",
        "import asyncio\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Initialize API key\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "MCP_SERVER_URL = \"http://localhost:8000/mcp\"\n",
        "\n",
        "async def main():\n",
        "    # Connect to your MCP server\n",
        "    mcp_client = Client(MCP_SERVER_URL)\n",
        "\n",
        "    # Fetch FastMCP tool definitions within the context manager\n",
        "    mcp_tools = []\n",
        "    async with mcp_client:\n",
        "        mcp_tools = await mcp_client.list_tools()\n",
        "\n",
        "    # Convert to OpenAI Assistant tool format\n",
        "    agent_tools = []\n",
        "    for tool in mcp_tools:\n",
        "        # OpenAI function tools require details to be nested under a 'function' key\n",
        "        agent_tools.append({\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": tool.name,\n",
        "                \"description\": tool.description if tool.description else \"\",\n",
        "                \"parameters\": tool.inputSchema\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # Create the assistant (formerly 'agent')\n",
        "    openai_client = OpenAI()\n",
        "    assistant = openai_client.beta.assistants.create(\n",
        "        model=\"gpt-4.1\",\n",
        "        name=\"MCP Assistant\",\n",
        "        instructions=\"Use the provided tools when helpful.\",\n",
        "        tools=agent_tools\n",
        "    )\n",
        "\n",
        "    print(\"Assistant created:\", assistant.id)\n",
        "\n",
        "    # Create a thread\n",
        "    thread = openai_client.beta.threads.create()\n",
        "\n",
        "    # Add a message to the thread\n",
        "    message = openai_client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=\"What is the weather in Seattle?\"\n",
        "    )\n",
        "\n",
        "    # Create and poll the run\n",
        "    run = openai_client.beta.threads.runs.create_and_poll(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant.id\n",
        "    )\n",
        "\n",
        "    # Handle tool calls if needed (simplified for this example)\n",
        "    if run.status == 'requires_action':\n",
        "        # In a real application, you would process run.required_action.submit_tool_outputs\n",
        "        # here, call the MCP server tools, and then submit the outputs back to OpenAI.\n",
        "        print(\"Run requires action. Tool calls need to be handled.\")\n",
        "\n",
        "    # Get the response\n",
        "    if run.status == 'completed':\n",
        "        messages = openai_client.beta.threads.messages.list(\n",
        "            thread_id=thread.id\n",
        "        )\n",
        "        # Print the last message from the assistant\n",
        "        if messages.data and messages.data[0].role == \"assistant\":\n",
        "            print(messages.data[0].content[0].text.value)\n",
        "        else:\n",
        "            print(\"No response from assistant or unexpected message format.\")\n",
        "    else:\n",
        "        print(f\"Run ended with status: {run.status}\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "id": "w5PdcCNeWQ98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}